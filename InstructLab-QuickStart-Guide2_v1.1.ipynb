{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c316749c-c5ba-46af-a667-cc89b9c6678c",
   "metadata": {},
   "source": [
    "# **Instruct Lab Quick Start Guide 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f69e85e-2633-4eec-aba3-efc573383c85",
   "metadata": {},
   "source": [
    "## **Generating synthetic dataset and Fine-Tuning the model**\n",
    "### **Before you begin**\n",
    "If you are going to fine-tune Granite model or any model of that size (7B) you need a **GPU instance with at least 24GB VRAM**.\n",
    "\n",
    "Make sure your working directory is **persist-vol**. This volume is a mounted external volume to provide data persistance. \n",
    "\n",
    "If you are running this on a runpod cloud GPU instance, data is not going to be persisted across instance reboots as cloud instances are ephemeral. \n",
    "\n",
    "So make sure you use **persist-vol** directory if you need to save the data. \n",
    "\n",
    "Also make sure that your Jupyter Notebook Guides (.ipynb) are located in **/home/instructlab/persist-vol** as otherwise some steps in this guide **might not work**\n",
    "\n",
    "Run the command below to see where is your working directory, it should be **/home/instructlab/persist-vol** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d405cbac-3314-4cfa-808f-53ce02d71767",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa67cc4-6bc8-4108-b3df-d8b7c492f3f3",
   "metadata": {},
   "source": [
    "## **STEP 1**\n",
    "### Download Granite model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b2088e8-4b95-4b3c-a2c0-df5d12c3f4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ilab model download \\\n",
    "--repository instructlab/granite-7b-lab-GGUF \\\n",
    "--filename granite-7b-lab-Q4_K_M.gguf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9f56aa-c7dd-4ad0-9f6e-0f366655490d",
   "metadata": {},
   "source": [
    "## **STEP 2**\n",
    "### Configure Instruct Lab to use Granite model \n",
    "We are going to change config.yaml to use Granite for chat and serving "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70ec2513-2f65-4971-bb50-30a752014f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i '/^\\s*model: models\\/merlinite-7b-lab-Q4_K_M.gguf\\s*$/s//  model: models\\/granite-7b-lab-Q4_K_M.gguf/' config.yaml\n",
    "!sed -i '/^\\s*model: models\\/merlinite-7b-lab-Q4_K_M.gguf\\s*$/s//  model: models\\/granite-7b-lab-Q4_K_M.gguf/' config.yaml\n",
    "!sed -i '/^\\s*host_port: 127\\.0\\.0\\.1:8000\\s*$/s//  host_port: 0.0.0.0:8000/' config.yaml\n",
    "!sed -i '/^\\s*model_path: models\\/merlinite-7b-lab-Q4_K_M.gguf\\s*$/s//  model_path: models\\/granite-7b-lab-Q4_K_M.gguf/' config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd638af-ffcb-498a-80cf-6c40d9c25184",
   "metadata": {},
   "source": [
    "Check the configuration file and confirm Granite model has been selected as default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba63f484-a83e-4832-badc-220aeeedeef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164bdb7d-c318-4eb1-832f-4d35257966ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## **STEP 3**\n",
    "### To test if Granite model works, start model serving and open chat \n",
    "```bash\n",
    "# Terminal window 1 \n",
    "ilab model serve \n",
    "\n",
    "# Terminal window 2\n",
    "ilab model chat \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7224c478-114e-4279-a34e-86e20b4cce8e",
   "metadata": {},
   "source": [
    "## **STEP 4**\n",
    "### Clone git repo with a sample files \n",
    "Within taxonomy directory, which is essentialy a way to structure your training data, we have these main directories: \n",
    "  - **knowledge** - directory that will contain qna.yaml document with factualy data and question/answer pairs.\n",
    "  - **compositional_skills** -\n",
    "  - **foundational_skills** - \n",
    "\n",
    "For the simplicity of this demo we will use just knowledge directory and will populate it with existing data from my GitHub repo. \n",
    "Run the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac165560-6df8-4f5f-ae77-0f6de4de95b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /home/instructlab/persist-vol/taxonomy/knowledge/fintech\n",
    "!cd /home/instructlab/persist-vol/taxonomy/knowledge/fintech \\\n",
    "&& git clone https://github.com/vitalijneverkevic/thoughtmachine.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d91cb81-708c-42c1-a9fc-e728768013c1",
   "metadata": {},
   "source": [
    "Inspect the the knowledge directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73b76d3e-0e42-4b89-8bb2-ab209c05b6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lah /home/instructlab/persist-vol/taxonomy/knowledge/fintech/thoughtmachine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f50f178-bb74-4cf3-a767-24218796142f",
   "metadata": {},
   "source": [
    "Inspect qna.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10cc7959-a8e3-4440-bf34-6c160bed6550",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat /home/instructlab/persist-vol/taxonomy/knowledge/fintech/thoughtmachine/qna.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891a0bf3-54e5-4810-a681-90b812660a9e",
   "metadata": {},
   "source": [
    "## About this dataset \n",
    "This dataset is about a company called Thought Machine, which is a FinTech company specilizing in providing modern software for internet banking. \n",
    "While you have Granit model running and chat window open ask the following questions about Thought Machine: \n",
    "  - Who is the CEO of Thought Machine and what is his background?\n",
    "  - Where did Paul Taylor of Thought Machine study?\n",
    "  - What role Paul Taylor holds at Thought Machine?\n",
    "\n",
    "You will see that Granit has some idea about Thought Machine, but sometimes it provides wrong information about who is the current CEO, wrong on certain specifics of the background of current CEO. \n",
    "Perhaps some of the data the model was trained on is now obsolete. \n",
    "\n",
    "So what we need to do is fine-tune the model and teach it so it's up to date. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189e3849-af2d-4d51-b60f-0af288734438",
   "metadata": {},
   "source": [
    "## **STEP 5**\n",
    "### Launch synthetic data generation \n",
    "For synthetic data generation to work make sure you have model server running. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19f5e05b-3680-4710-9ae2-f83cbef660ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ilab data generate \\\n",
    "--model models/granite-7b-lab-Q4_K_M.gguf \\\n",
    "--num-cpus 4 \\\n",
    "--num-instructions 50 \\\n",
    "--taxonomy-path /home/instructlab/persist-vol/taxonomy/knowledge/fintech/thoughtmachine/qna.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51c0448-751f-4d21-a149-cba8d50763d3",
   "metadata": {},
   "source": [
    "## **STEP 5**\n",
    "### Launch model fine-tuning\n",
    "Before you launch fine-tuning make sure you have model serving turned off.\n",
    "Also the output is better if you run this from the terminal, you can run this from the cell below, but you will have to scroll continually to observe the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fab850e-8aac-4ad4-96f7-ec6493a17855",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ilab model train \\\n",
    "--iters 50 \\\n",
    "--num-epochs 2 \\\n",
    "--device cuda"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
