{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9575a850-f567-469d-9724-f626080c0c3a",
   "metadata": {},
   "source": [
    "# **Instruct Lab Quick Start Guide 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c55bd2c-f3ce-4c80-8a3a-e106ab7d3294",
   "metadata": {},
   "source": [
    "## **Basic operations, model serving and chat**\n",
    "### **Before you begin**\n",
    "In this guide your working directory should be **persist-vol**. This volume is a mounted external volume to provide data persistance. \n",
    "\n",
    "If you are running this on a runpod cloud GPU instancee, data is not going to be persisted across instance reboots as cloud instances are ephemeral. \n",
    "\n",
    "So make sure you use **persist-vol** directory if you need to save the data. \n",
    "\n",
    "Also make sure that your Jupyter Notebook Guides (.ipynb) are located in **/home/instructlab/persist-vol** as otherwise some steps in this guide **might not work**\n",
    "\n",
    "Run the command below to see where is your working directory, it should be **/home/instructlab/persist-vol** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e803147e-0b4f-48be-b5a8-871f1fe946d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58da23fa-5e17-4f19-a7c7-daf137d6a0e4",
   "metadata": {},
   "source": [
    "## **STEP 1**\n",
    "### Initialize environment for InstructLab with defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cc63abb-d1cc-4dfc-a827-bf1cf9b05ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ilab init --non-interactive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469c1380-d44f-44aa-90a5-64315f8a8a7d",
   "metadata": {},
   "source": [
    "### Check the configuration file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e619e279-b3f0-44a9-91ec-46be9c2e4ec5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat /home/instructlab/persist-vol/config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35eeac64-8f6c-43df-b749-2d3b2d7e3447",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------\n",
    "We have 4 sections in this yaml config:\n",
    "  - settings for chat, like how big is the context window, which model to use, etc..\n",
    "  - settings for data generation like how many CPU cores to use, path to taxonomy (knowledge dataset)\n",
    "  - settings for serving models like the IP it will be available on, model path etc...\n",
    "\n",
    " For this demo and sake of simplicity let's leave it as is. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea17cd0-8dc5-424f-ba52-1b1d66d82711",
   "metadata": {},
   "source": [
    "## **STEP 2**\n",
    "### Download the default model, as currently none of the models are present on the machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8a0bdc-70c5-46fe-8f1c-788106eb0d64",
   "metadata": {},
   "source": [
    "This will use defaults from config.yaml and download instructlab/merlinite-7b-lab-GGUF.\n",
    "In the future the Granite models are going to be downloaded by default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2fd58c7-7d3e-4256-aa6f-f0cacb5e4315",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ilab model download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5553150-fe5b-4cce-be35-a7baf8f67ec2",
   "metadata": {},
   "source": [
    "### Once the model is downloaded let's check the \"models\" directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27ebf1a9-9295-4493-b0d6-fcba0d2db417",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lah /home/instructlab/persist-vol/models/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7c699d-b579-415e-a978-52c41acaf91d",
   "metadata": {},
   "source": [
    "---\n",
    "You can see the model is in the directory. From the filename you can see the model name is merlinite and it is a quantized to 4-bit precision. \n",
    "Here is the break down of a naming convention: \n",
    "\n",
    "In quantized model names like \"7B_Q4_K_M.gguf\", the \"K\" and \"M\" have specific meanings related to the quantization method used:\n",
    "\n",
    "- **\"K\"** stands for **\"K-quant\"** or **\"K-quantization\"**. This refers to a newer quantization method developed for the llama.cpp library that generally provides better perplexity (a measure of model quality) compared to older quantization techniques for the same model size.\n",
    "- **\"M\"** stands for **\"Medium\"**. It indicates the level of quantization within the K-quant method. The options typically include:\n",
    "  - **S**: Small (more heavily quantized)\n",
    "  - **M**: Medium\n",
    "  - **L**: Large (less heavily quantized)\n",
    "\n",
    "So, in the example \"merlinite-7b-lab-Q4_K_M.gguf\":\n",
    "- **7B**: Indicates a 7 billion parameter model\n",
    "- **Q4**: Represents 4-bit quantization\n",
    "- **K**: Signifies the use of K-quant method\n",
    "- **M**: Specifies the medium level of K-quant\n",
    "\n",
    "The K-quant models (like Q4_K_M) generally offer a good balance between model size, inference speed, and quality. They typically have less perplexity loss compared to older quantization methods like Q4_0 or Q4_1, while maintaining reasonable file sizes and inference speeds.\n",
    "\n",
    "However if resources allow, it is better to stick to less quantized models like 8-bit as these would offer even better performance and less halucinations. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7e1b93-e010-4fb8-b077-9dc1cd791fc2",
   "metadata": {},
   "source": [
    "## **STEP 3**\n",
    "### Serve the model\n",
    "\n",
    "In this step, **open new tab** in Jupyer Notebook and click on **\"Terminal\"** to open a new terminal, then paste the command below, that should start a server on localhost:8000\n",
    "```bash\n",
    "ilab model serve\n",
    "```\n",
    "\n",
    "Below you can take a look at the sample of --help command output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c641248f-13ed-4915-90bb-9454638fc998",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ilab model serve --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f17ad7a-2c41-4429-a2dd-2276d5b04c7f",
   "metadata": {},
   "source": [
    "# **STEP 4**\n",
    "### Start chat with the model \n",
    "In this step, **open another tab** in Jupyer Notebook and click on **\"Terminal\"** to open a second terminal, then paste the command below, that should start a chat. \n",
    "```bash\n",
    "ilab model chat\n",
    "```\n",
    "Below you can take a look at the sample of --help command output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f3dc571-0b8a-4f85-a48f-25191f57827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ilab model chat --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4605588b-09d7-422f-890b-475f7c1c6feb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Some tips while using the chat window \n",
    "  - to remove the frame type /p\n",
    "  - to start new chat /n\n",
    "  - to show more help /h\n",
    "  - to exit the chat type /q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9256eca6-e0a5-4040-a33f-6c78086570c7",
   "metadata": {},
   "source": [
    "# **STEP 5**\n",
    "### Exit chat and stop model serving\n",
    "- type **/q** to quit the chat in a chat terminal\n",
    "- In the terminal where model is served hit **Ctrl+C**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4314745-c2ba-421d-86ef-8d0dc0bb8963",
   "metadata": {},
   "source": [
    "# **FINISH**\n",
    "### This concludes the Guide 1 module"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
